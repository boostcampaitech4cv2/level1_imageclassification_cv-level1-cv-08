# BoostCamp AI Tech4 level-1-Mask Detection Project
***
## MemberğŸ”¥
| [ê¹€ë²”ì¤€](https://github.com/quasar529) | [ê¹€ì£¼í¬](https://github.com/alias26) | [ë°•ë¯¼ê·œ](https://github.com/zergswim) | [ì˜¤ì£¼í—Œ](https://github.com/OZOOOOOH) | [í—ˆê±´í˜](https://github.com/GeonHyeock) |
| :-: | :-: | :-: | :-: | :-: |
| <img src="https://avatars.githubusercontent.com/quasar529" width="100"> | <img src="https://avatars.githubusercontent.com/alias26" width="100"> | <img src="https://avatars.githubusercontent.com/zergswim" width="100"> | <img src="https://avatars.githubusercontent.com/OZOOOOOH" width="100"> | <img src="https://avatars.githubusercontent.com/GeonHyeock" width="100"> |
***
## Index
* [Demo Video](#demo-video)
* [Project Summary](#project-summary)
* [Requirements](#requirements)
* [Procedures](#procedures)
* [Features](#features)
* [Result](#result)
* [Conclusion](#Conclusion)  
***
## Demo Video
<img width="100%" src="/images/streamlit_demo.gif"/>
  

***
## Project Summary

#### ì£¼ì œ

- ì£¼ì–´ì§„ ì´ë¯¸ì§€ë¥¼ Mask, Gender, Ageë¡œ êµ¬ì„±ëœ 18ê°œì˜ í´ë˜ìŠ¤ ì¤‘ í•˜ë‚˜ë¡œ ì¶”ì¸¡í•˜ëŠ” Image Classificationì´ë‹¤.

#### ê°œìš” ë° ê¸°ëŒ€íš¨ê³¼

- Week1-5ê¹Œì§€ Computer Visionì— ëŒ€í•œ êµìœ¡ì´ ì§„í–‰ëê³ , Week6-7ì— ê·¸ë™ì•ˆ ë°°ìš´ ì´ë¡ ì„ ì ìš©í•  ìˆ˜ ìˆëŠ” Image ClassificationëŒ€íšŒë¥¼ ì§„í–‰í–ˆë‹¤. 
- ì´ë¥¼ í†µí•´ êµìœ¡ìƒì˜ í•™ìŠµ ì´í•´ë„ë¥¼ í™•ì¸ í•´ë³¼ ìˆ˜ ìˆê³  ì‹¤ì œ ë°ì´í„°ì— ì ìš©í•¨ì— ë”°ë¼ ì§„í–‰ ì¤‘ì¸ êµìœ¡ì˜ í•„ìš”ì„± ë° ì¤‘ìš”ì„±ì„ ë‹¤ì‹œ í•œ ë²ˆ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ì´ë¥¼ ì´ìš©í•´ ì–¼êµ´ ì‚¬ì§„ë§Œìœ¼ë¡œ Mask ì°©ìš© ìœ ë¬´ì™€ ë°”ë¥´ê²Œ ì°©ìš©í–ˆëŠ”ì§€ì— ëŒ€í•œ ìë™ íŒë³„ ê¸°ìˆ ë¡œ ì‚¬ìš© ê°€ëŠ¥í•˜ë‹¤.


#### ë°ì´í„° ì…‹ì˜ êµ¬ì¡°ë„

- ì „ì²´ ì‚¬ëŒ ìˆ˜ : 4,500ëª…
- í•œ ì‚¬ëŒë‹¹ ì‚¬ì§„ì˜ ê°œìˆ˜: 7ì¥
(ì°©ìš© 5ì¥, ì´ìƒí•˜ê²Œ ì°©ìš©(ì½”ìŠ¤í¬, í„±ìŠ¤í¬) 1ì¥, ë¯¸ì°©ìš© 1ì¥)
- ì´ë¯¸ì§€ í¬ê¸°: 384 x 512(width, height)
- ì „ì²´ ë°ì´í„°ì…‹ì€ 6:4 ë¹„ìœ¨ë¡œ Train, Testì…‹ìœ¼ë¡œ ì‚¬ìš©í•˜ê³  Testì…‹ì€ ì ˆë°˜ ì”© Public, Privateì…‹ìœ¼ë¡œ ì‚¬ìš©í•œë‹¤.
#### Data Description

|Class|Mask|Gender|AGE|
|---|---|---|---|
|0|Wear|Male|< 30|
|1|Wear|Male|>= 30 and < 60|
|2|Wear|Male|>= 60|
|3|Wear|Female|< 30|
|4|Wear|Female|>= 30 and < 60|
|5|Wear|Female|>= 60|
|6|Incorrect|Male|< 30|
|7|Incorrect|Male|>= 30 and < 60|
|8|Incorrect|Male|>= 60|
|9|Incorrect|Female|< 30|
|10|Incorrect|Female|>= 30 and < 60|
|11|Incorrect|Female|>= 60|
|12|Not Wear|Male|< 30|
|13|Not Wear|Male|>= 30 and < 60|
|14|Not Wear|Male|>= 60|
|15|Not Wear|Female|< 30|
|16|Not Wear|Female|>= 30 and < 60|
|17|Not Wear|Female|>= 60|
***
## Procedures

**[2022.10.20 ~ 2022.10.21]**  
í”„ë¡œì íŠ¸ì˜ ì‚¬ì „ê¸°íš ë‹¨ê³„ì—ì„œëŠ” í˜‘ì—…ì„ ìœ„í•´ ë™ì¼í•œ í…œí”Œë¦¿ ì‚¬ìš©ì„ ê³„íší–ˆì§€ë§Œ, ê°œì¸ì˜ ì´ˆê¸° ì•„ì´ë””ì–´ë¥¼ êµ¬í˜„í•  ìˆ˜ ìˆê²Œ ìì‹ ì—ê²Œ ë§ëŠ” í…œí”Œë¦¿ì„ í™œìš©í•˜ì—¬ ê°ì ì‘ì—…í–ˆë‹¤. ì´í›„ Baseì½”ë“œë¥¼ ì„ ì •í•˜ì—¬ Black í¬ë§·íŒ…ì„ ì‚¬ìš©í•˜ì—¬ í˜‘ì—…ì„ ì§„í–‰í•˜ê¸°ë¡œ í•˜ì˜€ë‹¤.

**[2022.10.24 ~ 2022.11.01]**  
Baseì½”ë“œ ì„ ì •ì¼(10.26)ê¹Œì§€ Baseì½”ë“œë¥¼ ë¯¸ì™„ì„±í•˜ê±°ë‚˜ ì¶”ê°€ ì‹¤í—˜ì„ ì›í•˜ëŠ” ì¸ì›ì´ ìƒê¹€ì— ë”°ë¼ Baseì½”ë“œ ì„ ì •ë‚ ì§œë¥¼ ë¯¸ë£¨ê²Œ ë˜ì—ˆë‹¤.

*ê°œì¸ë³„ ì£¼ìš” ì‹¤í—˜ ì „ëµ*
- ê¹€ë²”ì¤€(Loss,Optimizer,Augmentation), 
- ê¹€ì£¼í¬(Loss, Augmentation), 
- ë°•ë¯¼ê·œ((ë³„ë„ì§„í–‰) kfold), 
- ì˜¤ì£¼í—Œ(TRACER), 
- í—ˆê±´í˜(CLIP model)

**[2022.11.02 ~ 2022.11.03]**  
ëª¨ë‘ì˜ ì˜ê²¬ì„ ì¡´ì¤‘í•˜ì—¬ í˜‘ì—…ì„ í•  íŒ€ì›ê³¼ ê°œì¸ì´ í•˜ë˜ ì‹¤í—˜ì„ ë§ˆë¬´ë¦¬í•  íŒ€ì›ì„ ë‚˜ëˆ ì„œ ë‚¨ì€ ê¸°ê°„ ë™ì•ˆ í”„ë¡œì íŠ¸ë¥¼ ì§„í–‰í•˜ê²Œ ë˜ì—ˆë‹¤.
í˜‘ì—…ì€ Git-Flowë¥¼ ì´ìš©í–ˆê³  Baseì½”ë“œë¥¼ ì •í•œ í›„, í•„ìš”í•œ ê¸°ëŠ¥ì„ êµ¬í˜„í•´ ì¶”ê°€í–ˆë‹¤.
ê·¸ í›„ ê°œì¸ì˜ ê°€ì„¤ì— ë”°ë¼ ì‹¤í—˜ì„ ì§„í–‰í–ˆê³  ê°€ì¥ ë›°ì–´ë‚œ ì„±ëŠ¥(F1-Score)ì„ ë³´ì¸ ê²°ê³¼ë¥¼ ìµœì¢… ì œì¶œí–ˆë‹¤.  
ìµœì¢… ìˆœìœ„ : 12th / 20
***

## Features

**feat-multilabel** : 18ê°œì˜ Classë¥¼ ë¶„ë¥˜í•˜ëŠ” ë¬¸ì œë¥¼ 3ê°œì˜ Multi-Label Classë¡œ ë¶„ë¥˜í•˜ëŠ” ë¬¸ì œë¡œ ì¹˜í™˜, Multi loss ì¶”ê°€

**feat-TRACER** : ë°°ê²½ ì´ë¯¸ì§€ ì œê±°í•´ì£¼ëŠ” ê¸°ëŠ¥ ì¶”ê°€

**feat-wandb** : wandb, tqdm ì—°ë™

**feat-yml** : pytorch metric learningì˜ loss ì¶”ê°€

***
## Result
#### EDA
- ë°ì´í„° í´ë˜ìŠ¤ì— ë¶ˆê· í˜•ì´ ìˆëŠ” ì ì„ íŒŒì•…(ë‚˜ì´, ì„±ë³„)
- ë°ì´í„° í˜•ì‹ì€ ì „ì²´ì ìœ¼ë¡œ í†µì¼ë˜ì–´ ìˆìŒ(ì–¼êµ´ ìœ„ì¹˜)

#### ë°ì´í„° ì „ì²˜ë¦¬
- ì£¼ì–´ì§„ Train ë°ì´í„°ë¥¼ 9:1 ë¹„ìœ¨ë¡œ Train, Validationì…‹ìœ¼ë¡œ
ëª¨ë¸ í•™ìŠµì´ ì˜ ë˜ê³  ìˆëŠ”ì§€ì— ëŒ€í•´ ê²€ì¦í•˜ê¸° ìœ„í•´ì„œ ì‚¬ìš©
- ë°ì´í„°ê°€ ì‚¬ëŒ 1ëª…ê³¼ ë°°ê²½ë§Œ ìˆëŠ” ë‹¨ìˆœí•œ êµ¬ì¡°ì´ê¸° ë•Œë¬¸ì—
ì²˜ìŒì—ëŠ” Face Detection ëª¨ë¸ì„ ì´ìš©í•´ ì–¼êµ´ì„ Crop í›„
í•™ìŠµì„ ì§„í–‰í•˜ë ¤ í–ˆìœ¼ë‚˜ Maskë¥¼ ì“´ ì–¼êµ´ì€ ëª¨ë¸ì´ ì˜ íƒì§€í•˜ì§€ ëª»í•  ê±°ë¼ ì˜ˆìƒí•´ ë‹¤ë¥¸ ëª¨ë¸ì„ ì‚¬ìš©.
- RGB-Salient Object Detection Taskì—ì„œ TRACER ëª¨ë¸ì„ ì‚¬ìš©í•˜ê¸°ë¡œ ê²°ì •. ì´ ëª¨ë¸ì€ ì£¼ì–´ì§„ ì´ë¯¸ì§€ì—ì„œ Salient(í•µì‹¬ì ì¸) Objectë¥¼ ì°¾ì•„ì£¼ê³  Box í˜•íƒœê°€ ì•„ë‹Œ Segmentation í˜•íƒœë¡œ outputì´ ë‚˜ì˜¨ë‹¤. í•´ë‹¹ ëª¨ë¸ì´ ì‚¬ëŒë§Œ segmentationí•´ì¤„ ê²ƒìœ¼ë¡œ ì˜ˆìƒí•´ ì‚¬ìš©í–ˆê³  ê²°ê³¼ê°€ ê´œì°®ì•„ì„œ í•™ìŠµí•  ë•Œ ì‚¬ìš©í–ˆë‹¤.
 
#### Data Augmentation
- ResizeëŠ” ëª¨ë¸ì˜ í•™ìŠµê³¼ í•™ìŠµì‹œê°„ë‹¨ì¶•
- ShiftScaleRotateëŠ” ì¼ë°˜í™”, ë°ì´í„° Labelì˜ íŠ¹ì§•ì„ ìœ ì§€í•˜ê¸° ìœ„í•´ì„œ ì•½í•˜ê²Œ ë„£ì–´ì¤Œ(shift,scale 10%,rotation 5Â°)
- RandomBrightnessContrastëŠ” Maskê°€ í°ìƒ‰ ë§ê³  ë‹¤ë¥¸ ìƒ‰ë„ ìˆê¸° ë•Œë¬¸ì— ì¼ë°˜í™”ë¥¼ ìœ„í•´ì„œ ë°ê¸°ì™€ ëŒ€ì¡°ë¥¼ ì•„ì£¼ ì•½í•˜ê²Œ ë„£ì–´ì¤¬ë‹¤.(ê°ê° 20%)
- HorizontalFlipì€ ì¢Œìš° ë°˜ì „ì´ê¸° ë•Œë¬¸ì— ë‹¨ìˆœ ë°ì´í„° ì¦ê°•ì„ ìœ„í•´ ì‚¬ìš©
- CoarseDropoutì€ cut-outê¸°ë²•ìœ¼ë¡œ Overfitting ë°©ì§€ë¥¼ ìœ„í•´ ì‚¬ìš©
 
#### ëª¨ë¸ ê°œìš”
- ê¸°ë³¸ ëª¨ë¸ì€ ë¹ ë¥¸ ì‹¤í—˜ê³¼ ì•„ì´ë””ì–´ êµ¬í˜„ì„ ìœ„í•´ì„œ Efficientnet ê³„ì—´ ëª¨ë¸ì„ ì‚¬ìš©í•˜ê¸°ë¡œ ê²°ì •.
- Backboneìœ¼ë¡œ Efficientnetv2_së¥¼ ì´ìš©í•˜ì—¬ ê³µí†µëœ featureë¥¼ ì¶”ì¶œí•œ í›„, 3-Way fcë¥¼ í†µê³¼í•˜ì—¬ Mask, Gender, Age ê°ê°ì˜ Classë¥¼ ë¶„ë¥˜.
- Multi-Label ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•˜ì—¬ ê°ê°ì˜ Classì— ëŒ€í•˜ì—¬ Cross-entropy Lossë¥¼ ì„¤ì •í•˜ì—¬ ë”í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ì„¤ì •í•˜ì˜€ê³  ì¶”ê°€ë¡œ Data Imbalanceë¥¼ ê³ ë ¤í•˜ì—¬ Lossì— Weightë¥¼ ì¶”ê°€.

#### ì‹œì—° ê²°ê³¼
|<img width="100%" src="/images/wandb_loss.png"/>|<img width="100%" src="/images/wandb_accuracy.png"/>|<img width="100%" src="/images/wandb_f1score.png"/>|
|----|----|----|

|Submit/F1 Score|Submit/Accuracy|
|----|----|
|<div style="text-align: center">0.7040</div>|<div style="text-align: center">75.0635</div>|

***
## Conclusion
#### ì˜í•œ ì ë“¤
- íŒ€ ë‹¨ìœ„ë¡œ ì§„í–‰í•˜ê¸° ì „ ê°ì ìƒê°í•œ ê°€ì„¤ê³¼ ëŒ€ì‘í•˜ëŠ” ì „ëµì— ë”°ë¼ ë‹¤ì–‘í•œ ì‹¤í—˜ì„ ì§„í–‰í•´ ì´ì „ì— ì‹œë„í•˜ì§€ ëª»í•œ ë°©ë²•ì„ ì ìš©í•´ ë³¼ ìˆ˜ ìˆì—ˆë‹¤.
- íŒ€ìœ¼ë¡œ ì§„í–‰ í›„ì—ëŠ” git flowë¥¼ ì´ìš©í•œ í˜‘ì—…ì„ ê²½í—˜ í•  ìˆ˜ ìˆì—ˆë‹¤.
- Templateì„ ì‚¬ìš©í•´ ìµí˜ìœ¼ë¡œì„œ ë‹¤ë¥¸ ëŒ€íšŒ ë° í”Œë«í¼ì—ì„œë„ í™œìš©í•  ìˆ˜ ìˆê²Œ ë˜ì—ˆë‹¤.

#### ì•„ì‰¬ì› ë˜ ì ë“¤:
- git ì‚¬ìš© ì‹œ Issueë³„ë¡œ êµ¬ë¶„í•´ ì‚¬ìš© ëª»í–ˆë‹¤.
- ì‹œê°„ ë¶€ì¡±ìœ¼ë¡œ Ensemble ì‹œë„ ëª»í–ˆë‹¤.
- ê°œì¸ì ìœ¼ë¡œ ì‹¤í—˜ì„ í•  ë•Œ ë¬¸ì œê°€ ìƒê¸¸ ê²½ìš° í˜¼ìì„œ í•´ê²°í•´ì•¼ í•´ì„œ ë§ì€ ë…¸ë ¥ê³¼ ì‹œê°„ì´ ì†Œìš”ë˜ì–´ ë‹¤ì–‘í•œ ì‹œë„ë¥¼ í•  ì—¬ìœ ê°€ ë¶€ì¡±í–ˆë‹¤.

#### í”„ë¡œì íŠ¸ë¥¼ í†µí•´ ë°°ìš´ì :
- pytorch-template êµ¬ì¡° íŒŒì•…, ê¸°ëŠ¥ ì¶”ê°€ êµ¬í˜„ìœ¼ë¡œ ì¶”í›„ì— í™œìš© ê°€ëŠ¥.
- wandbë¥¼ í†µí•œ ì‹¤í—˜ í”¼ë“œë°±.
- Git Flowë¥¼ í†µí•œ í˜‘ì—… í”„ë¡œì„¸ìŠ¤ ì²´í—˜ ë° ì ìš© ê°€ëŠ¥.
- ì£¼ì–´ì§„ ë°ì´í„° ë¶„ì„ì„ ì² ì €íˆ ì§„í–‰ í›„ ì´ì— ëŒ€ì‘í•˜ëŠ” ì „ëµì„ ì„¸ì›Œì•¼ í•œë‹¤.
***
## Requirements
* Python >= 3.8 (3.8 recommended)
* PyTorch >= 1.2
* albumentations>=1.3.0
* tqdm
* wandb
* pytorch_metric_learning
* sklearn
* timm
* tensorboard >= 1.14
* Black == 22.10.0
***
## Folder Structure
  ```
  level1-imageclassification-cv-08/
  â”‚
  â”œâ”€â”€ train.py - main script to start training
  â”œâ”€â”€ test.py - evaluation of trained model
  â”‚
  â”œâ”€â”€ config.json - holds configuration for training
  â”œâ”€â”€ parse_config.py - class to handle config file and cli options
  â”‚
  â”œâ”€â”€ new_project.py - initialize new project with template files
  â”‚
  â”œâ”€â”€ TRACER/ - face detection modules
  â”‚
  â”œâ”€â”€ Base/ - abstract Base classes
  â”‚   â”œâ”€â”€ Base_data_loader.py
  â”‚   â”œâ”€â”€ Base_model.py
  â”‚   â””â”€â”€ Base_trainer.py
  â”‚
  â”œâ”€â”€ data_loader/ - anything about data loading goes here
  â”‚   â”œâ”€â”€ data_loaders.py
  â”‚   â””â”€â”€ transform.py
  â”‚
  â”œâ”€â”€ data/ - default directory for storing input data
  â”‚
  â”œâ”€â”€ model/ - models, losses, and metrics
  â”‚   â”œâ”€â”€ model.py
  â”‚   â”œâ”€â”€ metric.py
  â”‚   â””â”€â”€ loss.py
  â”‚
  â”œâ”€â”€ saved/
  â”‚   â”œâ”€â”€ models/ - trained models are saved here
  â”‚   â””â”€â”€ log/ - default logdir for tensorboard and logging output
  â”‚
  â”œâ”€â”€ trainer/ - trainers
  â”‚   â””â”€â”€ trainer.py
  â”‚
  â”œâ”€â”€ logger/ - module for tensorboard visualization and logging
  â”‚   â”œâ”€â”€ visualization.py
  â”‚   â”œâ”€â”€ logger.py
  â”‚   â””â”€â”€ logger_config.json
  â”‚  
  â”‚â”€â”€ utils/ - small utility functions
  â”‚   â””â”€â”€ util.py
  â”‚
  â””â”€â”€ submit/ - submission are saved here 
  ```
  ***
  ### Config file format
Config files are in `.json` format:
```javascript
{
    "name": "Mask_Base",                    // training session name
    "n_gpu": 1,                             // number of GPUs to use for training.
    "arch": {
        "type": "TimmModelMulti",
        "args": {
            "model_name": "efficientnetv2_rw_s",  // name of model architecture to train
            "pretrained": true
        }
    },
    "data_loader": {
        "type": "setup",                // selecting data loader
        "args": {
            "stage": "train",           // selecting the stage between train and eval
            "input_size": 240,          // image resize size
            "batch_size": 16,           // batch size
            "num_workers": 4            // number of cpu processes to be used for data loading
        }
    },
    "optimizer": {
        "type": "Adam",                 // optimizer type
        "args": {
            "lr": 0.0001,               // learning rate
            "weight_decay": 0,          // weight decay
            "amsgrad": true
        }
    },
    "loss": "all_loss",                 // loss type
    "loss_name": [
        [
            "focal",
            [
                1.4,            // multi_loss CE weight
                7.0,
                7.0
            ],
            0.375
        ],
        [
            "focal",
            [
                1.6285,
                2.5912
            ],
            0.25
        ],
        [
            "focal",
            [
                2.8723,
                3.9589,
                4.5075,
                14.0625,
                14.0625,
                28.4211
            ],
            0.375
        ]
    ],
    "metrics": [
        "accuracy", "f1" // list of metrics to evaluate
    ],
    "lr_scheduler": {
        "type": "StepLR", // learning rate scheduler type
        "args": {
            "step_size": 5,
            "gamma": 0.1
        }
    },
    "trainer": {
        "epochs": 50,             // number of training epochs
        "save_dir": "saved/",     // checkpoints are saved in save_dir/models/name
        "save_period": 1,         // save checkpoints every save_freq epochs
        "verbosity": 2,           // 0: quiet, 1: per epoch, 2: full
        "monitor": "min val/loss",// mode and metric for model performance monitoring. set 'off' to disable.
        "early_stop": 3,          // number of epochs to wait before early stop. set 0 to disable.
        "tensorboard": false     // enable tensorboard visualization
    },
    "wandb": true,   // enable wandb logging
    "visualize": false, // enable visualization of wandb visualization
    "submit_dir": "/submit", // submission csv directory
    "info_dir": "/input/data/eval"// eval dataset directory
}
```

**Add addional configurations if you need.**

### Train, Test using config files
Modify `config.json` by your setting:

  ```
  python train.py --config config.json
  
  python test.py --config config.json --resume "Your Checkpoint Path"
  ```

### Streamlit Prediction
Run and Check your Mask Classification Prediction result:

```
streamlit run app.py --server.port="Your Port Number"
```

## License
[This project is licensed under the MIT License. See  LICENSE for more details](https://github.com/victoresque/pytorch-template)
